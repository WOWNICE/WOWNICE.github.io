<!DOCTYPE html>
<html lang="">
    <!-- title -->




<!-- keywords -->




<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="author" content="Haizhou Shi">
    <meta name="renderer" content="webkit">
    <meta name="copyright" content="Haizhou Shi">
    
    <meta name="keywords" content="hexo,hexo-theme,hexo-blog">
    
    <meta name="description" content>
    <meta http-equiv="Cache-control" content="no-cache">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Graph Neural Networks - Survey · N1H111SM&#39;s Miniverse</title>
    <style type="text/css">
    @font-face {
        font-family: 'Oswald-Regular';
        src: url("/font/Oswald-Regular.ttf");
    }

    body {
        margin: 0;
    }

    header,
    footer,
    .back-top,
    .sidebar,
    .container,
    .site-intro-meta,
    .toc-wrapper {
        display: none;
    }

    .site-intro {
        position: relative;
        z-index: 3;
        width: 100%;
        /* height: 50vh; */
        overflow: hidden;
    }

    .site-intro-placeholder {
        position: absolute;
        z-index: -2;
        top: 0;
        left: 0;
        width: calc(100% + 300px);
        height: 100%;
        background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
        background-position: center center;
        transform: translate3d(-226px, 0, 0);
        animation: gradient-move 2.5s ease-out 0s infinite;
    }

    @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }

</style>

    <link rel="preload" href="/css/style.css?v=20180824" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <link rel="stylesheet" href="/css/mobile.css?v=20180824" media="(max-width: 980px)">
    
    <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    
    <!-- /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
/* This file is meant as a standalone workflow for
- testing support for link[rel=preload]
- enabling async CSS loading in browsers that do not support rel=preload
- applying rel preload css once loaded, whether supported or not.
*/ -->
<script>
(function( w ){
	"use strict";
	// rel=preload support test
	if( !w.loadCSS ){
		w.loadCSS = function(){};
	}
	// define on the loadCSS obj
	var rp = loadCSS.relpreload = {};
	// rel=preload feature support test
	// runs once and returns a function for compat purposes
	rp.support = (function(){
		var ret;
		try {
			ret = w.document.createElement( "link" ).relList.supports( "preload" );
		} catch (e) {
			ret = false;
		}
		return function(){
			return ret;
		};
	})();

	// if preload isn't supported, get an asynchronous load by using a non-matching media attribute
	// then change that media back to its intended value on load
	rp.bindMediaToggle = function( link ){
		// remember existing media attr for ultimate state, or default to 'all'
		var finalMedia = link.media || "all";

		function enableStylesheet(){
			link.media = finalMedia;
		}

		// bind load handlers to enable media
		if( link.addEventListener ){
			link.addEventListener( "load", enableStylesheet );
		} else if( link.attachEvent ){
			link.attachEvent( "onload", enableStylesheet );
		}

		// Set rel and non-applicable media type to start an async request
		// note: timeout allows this to happen async to let rendering continue in IE
		setTimeout(function(){
			link.rel = "stylesheet";
			link.media = "only x";
		});
		// also enable media after 3 seconds,
		// which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
		setTimeout( enableStylesheet, 3000 );
	};

	// loop through link elements in DOM
	rp.poly = function(){
		// double check this to prevent external calls from running
		if( rp.support() ){
			return;
		}
		var links = w.document.getElementsByTagName( "link" );
		for( var i = 0; i < links.length; i++ ){
			var link = links[ i ];
			// qualify links to those with rel=preload and as=style attrs
			if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
				// prevent rerunning on link
				link.setAttribute( "data-loadcss", true );
				// bind listeners to toggle media back
				rp.bindMediaToggle( link );
			}
		}
	};

	// if unsupported, run the polyfill
	if( !rp.support() ){
		// run once at least
		rp.poly();

		// rerun poly on an interval until onload
		var run = w.setInterval( rp.poly, 500 );
		if( w.addEventListener ){
			w.addEventListener( "load", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		} else if( w.attachEvent ){
			w.attachEvent( "onload", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		}
	}


	// commonjs
	if( typeof exports !== "undefined" ){
		exports.loadCSS = loadCSS;
	}
	else {
		w.loadCSS = loadCSS;
	}
}( typeof global !== "undefined" ? global : this ) );
</script>

    <link rel="icon" href="/assets/Goku_1.ico">
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js" as="script">
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" as="script">
    <link rel="preload" href="/scripts/main.js" as="script">
    <link rel="preload" as="font" href="/font/Oswald-Regular.ttf" crossorigin>
    <link rel="preload" as="font" href="https://at.alicdn.com/t/font_327081_1dta1rlogw17zaor.woff" crossorigin>
    
    <!-- fancybox -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script>
    <!-- 百度统计  -->
    
    <!-- 谷歌统计  -->
    
</head>

    
        <body class="post-body">
    
    
<header class="header">

    <div class="read-progress"></div>
    <div class="header-sidebar-menu">&#xe775;</div>
    <!-- post页的toggle banner  -->
    
    <div class="banner">
            <div class="blog-title">
                <a href="/">N1H111SM&#39;s Miniverse</a>
            </div>
            <div class="post-title">
                <a href="#" class="post-name">Graph Neural Networks - Survey</a>
            </div>
    </div>
    
    <a class="home-link" href="/">N1H111SM's Miniverse</a>
</header>
    <div class="wrapper">
        <div class="site-intro" style="







height:50vh;
">
    
    <!-- 主页  -->
    
    
    <!-- 404页  -->
            
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-img" style="background-image: url(/intro/poker_1.jpg)"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
            Graph Neural Networks - Survey
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
            
            <!-- 404 -->
            
        </p>
        <!-- 文章页meta -->
        
            <div class="post-intros">
                <!-- 文章页标签  -->
                
                    <div class="post-intro-tags">
    
        <a class="post-tag" href="javascript:void(0);" data-tags="GNN">GNN</a>
    
</div>
                
                
                    <div class="post-intro-read">
                        <span>字数统计: <span class="post-count word-count">4.8k</span>阅读时长: <span class="post-count reading-time">22 min</span></span>
                    </div>
                
                <div class="post-intro-meta">
                    <span class="post-intro-calander iconfont-archer">&#xe676;</span>
                    <span class="post-intro-time">2020/02/28</span>
                    
                    <span id="busuanzi_container_page_pv" class="busuanzi-pv">
                        <span class="iconfont-archer">&#xe602;</span>
                        <span id="busuanzi_value_page_pv"></span>
                    </span>
                    
                    <span class="shareWrapper">
                        <span class="iconfont-archer shareIcon">&#xe71d;</span>
                        <span class="shareText">Share</span>
                        <ul class="shareList">
                            <li class="iconfont-archer share-qr" data-type="qr">&#xe75b;
                                <div class="share-qrcode"></div>
                            </li>
                            <li class="iconfont-archer" data-type="weibo">&#xe619;</li>
                            <li class="iconfont-archer" data-type="qzone">&#xe62e;</li>
                            <li class="iconfont-archer" data-type="twitter">&#xe634;</li>
                            <li class="iconfont-archer" data-type="facebook">&#xe67a;</li>
                        </ul>
                    </span>
                </div>
            </div>
        
    </div>
</div>
        <script>
 
  // get user agent
  var browser = {
    versions: function () {
      var u = window.navigator.userAgent;
      return {
        userAgent: u,
        trident: u.indexOf('Trident') > -1, //IE内核
        presto: u.indexOf('Presto') > -1, //opera内核
        webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
        gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
        mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
        ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
        android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
        iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
        iPad: u.indexOf('iPad') > -1, //是否为iPad
        webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
        weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
        uc: u.indexOf('UCBrowser') > -1 //是否为android下的UC浏览器
      };
    }()
  }
  console.log("userAgent:" + browser.versions.userAgent);

  // callback
  function fontLoaded() {
    console.log('font loaded');
    if (document.getElementsByClassName('site-intro-meta')) {
      document.getElementsByClassName('intro-title')[0].classList.add('intro-fade-in');
      document.getElementsByClassName('intro-subtitle')[0].classList.add('intro-fade-in');
      var postIntros = document.getElementsByClassName('post-intros')[0]
      if (postIntros) {
        postIntros.classList.add('post-fade-in');
      }
    }
  }

  // UC不支持跨域，所以直接显示
  function asyncCb(){
    if (browser.versions.uc) {
      console.log("UCBrowser");
      fontLoaded();
    } else {
      WebFont.load({
        custom: {
          families: ['Oswald-Regular']
        },
        loading: function () {  //所有字体开始加载
          // console.log('loading');
        },
        active: function () {  //所有字体已渲染
          fontLoaded();
        },
        inactive: function () { //字体预加载失败，无效字体或浏览器不支持加载
          console.log('inactive: timeout');
          fontLoaded();
        },
        timeout: 5000 // Set the timeout to two seconds
      });
    }
  }

  function asyncErr(){
    console.warn('script load from CDN failed, will load local script')
  }

  // load webfont-loader async, and add callback function
  function async(u, cb, err) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (cb) { o.addEventListener('load', function (e) { cb(null, e); }, false); }
    if (err) { o.addEventListener('error', function (e) { err(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }

  var asyncLoadWithFallBack = function(arr, success, reject) {
      var currReject = function(){
        reject()
        arr.shift()
        if(arr.length)
          async(arr[0], success, currReject)
        }

      async(arr[0], success, currReject)
  }

  asyncLoadWithFallBack([
    "https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js", 
    "https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js",
    "/lib/webfontloader.min.js"
  ], asyncCb, asyncErr)
</script>        
        <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
        <div class="container container-unloaded">
            <main class="main post-page">
    <article class="article-entry">
        <p><strong>Materials</strong>:</p>
<ul>
<li><a href="https://github.com/thunlp/GNNPapers" target="_blank" rel="noopener">github repo “GNN papers one must read”</a></li>
<li><a href="https://arxiv.org/abs/1901.00596" target="_blank" rel="noopener">paper “A Comprehensive Survey on Graph Neural Networks”</a></li>
<li><a href="https://shihaizhou.com/2020/02/22/Graph-Neural-Networks-Basics/" target="_blank" rel="noopener">Previous post introducing basic knowledge about GNNs.</a></li>
</ul>
<h1 id="Backgrounds"><a href="#Backgrounds" class="headerlink" title="Backgrounds"></a>Backgrounds</h1><h2 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h2><p><strong>History</strong> 早期的工作可以被归结为Recurrent GNNs (RecGNN)，节点在每个iteration和周围的节点传递信息直到节点的表示拟合，这种方法在计算上开销比较大，后来的研究者为了解决这一问题也有工作。CNN在视觉领域取得成功之后，研究者在GNN上重新定义了convolution操作并且有很多的工作围绕ConvGNN展开。在ConvGNN中可以分为两个小的子方向：spatial-based ConvGNNs以及spectral-based ConvGNNs。除此之外，还有很多工作关注在Graph AutoEncoders以及Spatial-Temporal GNNs，这些工作都是在前两个方向的基础上进行的。</p>
<p><strong>GNN vs Graph Kernel</strong> 后者是以往解决graph classification的主流方法，这个方法通过核函数将图结构映射到一个低维的向量空间，然后利用ML方法例如SVM进行分类。和GNN不同的是，Graph Kernel方法里的核函数是人为定义的而不是可学习的。GNN则将Graph Representation直接进行端到端的训练学习。</p>
<h2 id="Training-Frameworks"><a href="#Training-Frameworks" class="headerlink" title="Training Frameworks"></a>Training Frameworks</h2><p><strong>Semi-supervised learning for node-level classification.</strong> 在节点上进行的<strong>半监督分类问题</strong>。半监督意味着在一个图中有一些节点进行了标注，而另外一些节点没有标注。通常使用ConvGNN进行未标注节点的分类。</p>
<p><strong>Supervised learning for graph-level classification.</strong> Graph-level的有监督分类。通常使用graph convolution + graph pooling/readout layer进行。graph pooling layer通常被用来进行高维信息的聚合，readout layer将每个节点的representation映射到graph-level的representation。</p>
<p><strong>Unsupervised learning for graph embedding.</strong> 在没有标注的情况下学习图像的embedding。一种方法采用autoencoder；另一种方法采用negative sampling：采样一些互相没有连接的node pair作为负样本，有连接的node pair作为正样本。</p>
<h1 id="RecGNNs"><a href="#RecGNNs" class="headerlink" title="RecGNNs"></a>RecGNNs</h1><p>RecGNNs是最早开始在图结构上采用神经网络的，可以说是GNNs方法的先驱。早期的工作因为计算条件的限制，只能在directed acyclic graphs上进行。</p>
<p>由<a href="http://persagen.com/files/misc/scarselli2009graph.pdf" target="_blank" rel="noopener">Scarselli et al.提出的GNN*</a>算是图神经网络的开山之作，它采用了一种information diffusion mechanism - it updates nodes’ states by exchanging neighborhood information recurrently until a stable equilibrium is reached: </p>
<script type="math/tex; mode=display">
h_v^{(t)} = \sum_{u\in N(v)} f(x_v, x_{(v,u)}^e,x_u, h_u^{(t-1)})</script><p>To ensure convergence, the recurrent function $f(\cdot)$ <strong>must be a contraction mapping</strong>, which shrinks the distance between two points after projecting them into a latent space. In the case of $f(\cdot)$ being a neural network, a penalty term has to be imposed on the Jacobian matrix of parameters.</p>
<p><a href="https://ieeexplore.ieee.org/document/5596796" target="_blank" rel="noopener">Graph Echo State Network (GraphESN)</a> 在GCN*的基础上进行了改进从而达到了更好的训练效率 - It implements a contractive state transition function to recurrently update node states until the global graph state reaches convergence. Afterward, the output layer is trained by taking the fixed node states as inputs. （该工作的引用不是很高）</p>
<p><a href="https://arxiv.org/pdf/1511.05493.pdf" target="_blank" rel="noopener">Gated Graph Neural Network (GGNN)</a> 采用了GRU作为recurrent function. </p>
<script type="math/tex; mode=display">
h_v^{(t)}=\text{GRU}(h_v^{(t-1)}, \sum_{u\in N(v)}Wh_u^{(t-1)})</script><p>同时GGNN不再将convergence作为recurrence停止的信号，而是将其限制在一个最大步数里。这样做的好处是不再需要对参数进行额外的约束来保证收敛，同时它采用了BP进行参数更新：这在graph很大的时候可能会导致问题。</p>
<p><a href="http://proceedings.mlr.press/v80/dai18a/dai18a.pdf" target="_blank" rel="noopener">Stochastic Steady-state Embedding (SSE)</a>对于更大的图上有比较好的表现。他对于节点hidden state的更新采用的是随机且异步(stochastic and asynchronous)的方式：它会sample一部分的节点进行更新，并且sample另一部分的节点进行梯度计算。为了让算法更加稳定，在进行hidden state的更新时还会采用smoothing的方法。</p>
<script type="math/tex; mode=display">
h_v^{(t)} = (1-\alpha)h_v^{(t-1)} + \alpha W_1 \sigma(W_2[x_v, \sum_{u\in N(v)}[h_u^{(t-1)}, x_u]])</script><p>注意：SSE并没有在理论上证明通过以上的recurrence能够收敛。</p>
<h1 id="ConvGNNs"><a href="#ConvGNNs" class="headerlink" title="ConvGNNs"></a>ConvGNNs</h1><p>首先我们会介绍关于<a href="https://shihaizhou.com/2020/02/22/Graph-Neural-Networks-Basics/" target="_blank" rel="noopener">Graph Laplacian Operator的intuition和推导</a>过程，因为这是一个非常重要的概念，理解它有助于理解图结构的问题应当遵循怎样的解决思路。接着分别介绍Spectral-based ConvGNNs和Spatial-based ConvGNNs.</p>
<h2 id="Spectral-based-ConvGNNs"><a href="#Spectral-based-ConvGNNs" class="headerlink" title="Spectral-based ConvGNNs"></a>Spectral-based ConvGNNs</h2><p>Spectral-based approaches define graph convolutions by introducing filters from the perspective of graph signal processing where the graph convolutional operation is interpreted as removing noises from graph signals. </p>
<p>首先回顾graph convolution的定义：The <strong>graph convolution</strong> of the input signal $x$ with a filter $g\in \mathbb R^{|V|}$ is defined as</p>
<script type="math/tex; mode=display">
\begin{aligned} \mathbf{x} *_{G} \mathbf{g} &=\mathscr{F}^{-1}(\mathscr{F}(\mathbf{x}) \odot \mathscr{F}(\mathbf{g})) \\ &=\mathbf{U}\left(\mathbf{U}^{T} \mathbf{x} \odot \mathbf{U}^{T} \mathbf{g}\right) \\
&= \mathbf{U} \mathbf{g}_\theta \mathbf{U}^T \mathbf{x}
\end{aligned}</script><p><a href="https://arxiv.org/abs/1312.6203" target="_blank" rel="noopener">Spectral Convolutional Neural Network (Spectral CNN)</a> 假设了多层的可训练multi-channel filter $\mathbf{g}_{\theta}=\mathbf{\Theta}_{i, j}^{(k)}$. Spectral CNN的图卷积操作定义为：</p>
<script type="math/tex; mode=display">
\mathbf{H}_{:, j}^{(k)}=\sigma\left(\sum_{i=1}^{f_{k-1}} \mathbf{U} \Theta_{i, j}^{(k)} \mathbf{U}^{T} \mathbf{H}_{:, i}^{(k-1)}\right) \quad\left(j=1,2, \cdots, f_{k}\right)</script><p>where $k$ is the layer index, $\mathbf{H}^{(k-1)} \in \mathbf{R}^{n \times f_{k-1}}$ is the input graph signal, $\mathbf{H}^{(0)}=\mathbf{X}$, $f_{k-1}$ is the number of input channels and $f_k$ is the number of output channels, $\Theta_{i, j}^{(k)}$ is a diagonal matrix filled with learnable parameters. </p>
<p>因为需要特征分解，所以Spectral CNN方法有以下三点不足：首先，任何图结构的变化（边权变化或者节点增加）都会导致eigenbasis的变化；其次，训练得到的fitler是domain dependent，是不能运用在不同结构的图上的；第三，特征分解需要$O(|V|^3)$的计算复杂度。以下的两篇工作ChebNet和GCN通过一些近似和简化将其计算复杂度降低。</p>
<p><a href="https://arxiv.org/abs/1606.09375" target="_blank" rel="noopener">Chebyshev Spectral CNN (ChebNet)</a> 认为non-parametric filters有两点不足：(i) they are not localized in space; (ii) their learning complexity is in $O(n)$. 根据<a href="https://shihaizhou.com/2020/02/22/Graph-Neural-Networks-Basics/" target="_blank" rel="noopener">上一篇博客</a>中的Lemma 1，我们可以通过高次$L_n$来得到具有局部连通性的filter. 所以我们可以如下设计一个多channel的filter函数：</p>
<script type="math/tex; mode=display">
g_{\theta}(\Lambda)=\sum_{k=0}^{K-1} \theta_{k} \Lambda ^k</script><p>高次$L_n$的计算需要$O(N^3)$的复杂度，而我们最后期待计算的结果是类似于将filter函数作用到输入的graph signal $x$上。据此联想到Chebyshev Polynomials（详细见博客”Approximation Theory”中描述Chebyshev Polynomials的定义及性质）在方阵上的推广。为了满足Chebyshev Polynomials的定义域问题，需要将$\Lambda$以及$L$归一化到区间$[-1,1]$上：</p>
<script type="math/tex; mode=display">
\begin{align}
\tilde {\Lambda} &= \frac {2\Lambda} {\lambda_\max} - I \\
\tilde {L} &= \frac {2 L} {\lambda_\max} - I
\end{align}</script><p>Chebyshev Polynomials的递归定义如下：</p>
<script type="math/tex; mode=display">
T_{i}(\mathbf{x})=2 \mathbf{x} T_{i-1}(\mathbf{x})-T_{i-2}(\mathbf{x})</script><p>其中$T_{0}(\mathbf{x})=1$, $T_{1}(\mathbf{x})=\mathbf{x}$, $\mathbf{x}$为向量。根据以上我们能够给出更快计算filter的定义式：</p>
<script type="math/tex; mode=display">
\mathbf{x} *_{G} \mathbf{g}_{\theta}=\sum_{i=0}^{K} \theta_{i} T_{i}(\tilde{\mathbf{L}}) \mathbf{x}</script><p>As an improvement over Spectral CNN, the filters defined by ChebNet are localized in space, which means filters can extract local features independently of the graph size. </p>
<p><a href="https://arxiv.org/pdf/1609.02907.pdf" target="_blank" rel="noopener">Graph Convolutional Network (GCN)</a> 对ChebNet进行了一阶近似，通过固定$K=1$，$\lambda_\max=2$，我们能够将上式改写成：</p>
<script type="math/tex; mode=display">
\mathbf{x} *_{G} \mathbf{g}_{\theta}=\theta_{0} \mathbf{x}-\theta_{1} \mathbf{D}^{-\frac{1}{2}} \mathbf{A} \mathbf{D}^{-\frac{1}{2}} \mathbf{x}</script><p>To restrain the number of parameters and avoid over-fitting, GCN further assume $\theta =\theta_0=-\theta_1$, leading to the following definition of a graph convolution, </p>
<script type="math/tex; mode=display">
\mathbf{x} *_{G} \mathbf{g}_{\theta}=\theta\left(\mathbf{I}_{\mathbf{n}}+\mathbf{D}^{-\frac{1}{2}} \mathbf{A} \mathbf{D}^{-\frac{1}{2}}\right) \mathbf{x}</script><p>为了能够处理多通道的input/output，GCN将上式改成了compositional layer, defined as,</p>
<script type="math/tex; mode=display">
\mathbf{H}=\mathbf{X} *_{G} \mathbf{g}_{\Theta}=f(\overline{\mathbf{A}} \mathbf{X} \Theta)</script><p>其中$\overline{\mathbf{A}}=\mathbf{I}_{\mathbf{n}}+\mathbf{D}^{-\frac{1}{2}} \mathbf{A} \mathbf{D}^{-\frac{1}{2}}$, $f(\cdot)$是activation function，使用这样定义的$\overline A$会导致numerical instability. To address this problem, GCN applies a normalization trick: $\overline{\mathbf{A}}=\tilde{\mathbf{D}}^{-\frac{1}{2}} \tilde{\mathbf{A}} \tilde{\mathbf{D}}^{-\frac{1}{2}}$ with $\tilde{\mathbf{A}}=\mathbf{A}+\mathbf{I}_{\mathbf{n}}$ and $\tilde{\mathbf{D}}_{i i}=\sum_{j} \tilde{\mathbf{A}}_{i j}$. 虽然GCN是一种Spectral-based的方法，但是它也能够被看作aggregating feature information from a node’s neighborhood的空间图卷积网络,</p>
<script type="math/tex; mode=display">
\mathbf{h}_{v}=f(\boldsymbol{\Theta}^{T}(\sum_{u \in\{N(v) \cup v\}} \bar{A}_{v, u} \mathbf{x}_{u})) \quad \forall v \in V</script><p>在GCN的基础上，有很多的工作进行了一些增量式的改动。Several recent works made incremental improvements over GCN by exploring alternative symmetric matrices. <a href="https://arxiv.org/pdf/1801.03226.pdf" target="_blank" rel="noopener">Adaptive Graph Convolutional Network (AGCN)</a> learns hid-den structural relations unspecified by the graph adjacency matrix. It constructs a so-called residual graph adjacency matrix through a learnable distance function which takes two nodes’ features as inputs. <a href="https://arxiv.org/pdf/1706.02216.pdf" target="_blank" rel="noopener">Dual Graph Convolutional Network (DGCN)</a> introduces a dual graph convolutional architecture with two graph convolutional layers in parallel.</p>
<h2 id="Spatial-based-ConvGNNs"><a href="#Spatial-based-ConvGNNs" class="headerlink" title="Spatial-based ConvGNNs"></a>Spatial-based ConvGNNs</h2><p>Spatial-based approaches inherit ideas from RecGNNs to define graph convolutions by information propagation. The spatial graph convolutional operation essentially propagates node information along edges.</p>
<p>在二维图像上的convolution可以看作是graph convolution的特殊情况（如下图所示）：图像中，红点的representation是weighted sum of the nearby representation；同样的，基于这个想法我们可以定义一个图的convolution为他的weighted sum of the neighborhood。</p>
<p><img src="https://i.loli.net/2020/02/25/Kwto9fgQyN7r6XH.png" alt="image.png"></p>
<p><a href="https://ieeexplore.ieee.org/document/4773279" target="_blank" rel="noopener">Neural Network for Graphs (NN4G)</a> 是和GNN*同一时间提出来的模型。和RecGNNs不同的是，NN4G层之间不共享参数，除此之外，层与层之间还有residual connection。这和之前的GCN有很强的相似性，只是NN4G没有采用normalization的技术，这会导致层与层之间的表示在scale上有非常大的差别。从这里我们可以想到，<strong>一定要注意最简单的常识性问题。例如算法是否收敛，设计的模型是否会导致参数的爆炸，每一层的scale是多少，都要有一些意识。</strong>深度学习虽然像是在很多基本块中找合适的零件搭积木，但是关于模型设计的技术细节，还是需要多加注意。</p>
<script type="math/tex; mode=display">
\mathbf{H}^{(k)}=f\left(\mathbf{X} \mathbf{W}^{(k)}+\sum_{i=1}^{k-1} \mathbf{A} \mathbf{H}^{(k-1)} \mathbf{\Theta}^{(k)}\right)</script><ul>
<li><a href="https://arxiv.org/abs/1511.02136" target="_blank" rel="noopener">Diffusion Convolutional Neural Network (DCNN)</a></li>
<li><a href="https://arxiv.org/abs/1707.01926" target="_blank" rel="noopener">Diffusion Graph Convolution (DGC)</a></li>
<li><a href="https://arxiv.org/abs/1811.10435" target="_blank" rel="noopener">PGC-DGCNN</a></li>
<li><a href="https://arxiv.org/abs/1801.07455" target="_blank" rel="noopener">Partition Graph Convolution (PGC)</a></li>
</ul>
<p><a href="https://arxiv.org/abs/1704.01212" target="_blank" rel="noopener">Message Passing Neural Network (MPNN)</a> outlines a general framework of spatial-based ConvGNNs. 这篇工作将图卷积看作是message passing的一种方式，节点信息通过边进行传递。message passing机制定义为以下：</p>
<script type="math/tex; mode=display">
\mathbf{h}_{v}^{(k)}=U_{k}\left(\mathbf{h}_{v}^{(k-1)}, \sum_{u \in N(v)} M_{k}\left(\mathbf{h}_{v}^{(k-1)}, \mathbf{h}_{u}^{(k-1)}, \mathbf{x}_{v u}^{e}\right)\right)</script><p>其中第零层的隐层表示为节点输入，$U_k(\cdot)​$ 以及 $M_k(\cdot)​$ 是具有可学习参数的函数。经过几段的message passing，$h_v^{(K)}​$能够直接传进output layer进行node-level prediction或者进入一个readout function进行graph-level prediction. readout function基于节点表示生成图表示：</p>
<script type="math/tex; mode=display">
\mathbf{h}_{G}=R\left(\mathbf{h}_{v}^{(K)} | v \in G\right)</script><p><a href="https://arxiv.org/abs/1810.00826" target="_blank" rel="noopener">Graph Isomorphism Network (GIN)</a> finds that previous MPNN-based <strong>methods are incapable of distinguishing different graph structures</strong> based on the graph embedding they produced. 为了弥补这个缺点，GIN将中心节点的权重用一个可学习参数来代替：</p>
<script type="math/tex; mode=display">
\mathbf{h}_{v}^{(k)}=M L P\left(\left(1+\epsilon^{(k)}\right) \mathbf{h}_{v}^{(k-1)}+\sum_{u \in N(v)} \mathbf{h}_{u}^{(k-1)}\right)</script><p><a href="https://arxiv.org/abs/1706.02216" target="_blank" rel="noopener">GraphSage</a> 不直接让所有的邻接节点进行message passing，因为一个节点可能有非常不同的邻接节点数，如果直接全部计算会有较大的计算开销。因此这篇工作采取了从一个节点的neighborhodd中采样固定数目节点的方法，其中$S_{\mathcal{N}(v)}$表示采样，其中的aggregation function $f_k$必须是一个顺序无关的函数例如mean, sum or max：</p>
<script type="math/tex; mode=display">
\mathbf{h}_{v}^{(k)}=\sigma\left(\mathbf{W}^{(k)} \cdot f_{k}\left(\mathbf{h}_{v}^{(k-1)},\left\{\mathbf{h}_{u}^{(k-1)}, \forall u \in S_{\mathcal{N}(v)}\right\}\right)\right)</script><p><a href="https://arxiv.org/abs/1710.10903" target="_blank" rel="noopener">Graph Attention Network (GAT)</a>  和之前的模型不同，它认为message passing中的不同节点应该有不同的权重。这权重也是通过训练学习得到的。GAT中的图卷积定义为：</p>
<script type="math/tex; mode=display">
\mathbf{h}_{v}^{(k)}=\sigma\left(\sum_{u \in \mathcal{N}(v) \cup v} \alpha_{v u}^{(k)} \mathbf{W}^{(k)} \mathbf{h}_{u}^{(k-1)}\right)</script><p>其中的$\alpha _{vu}^k$表示的第$k$层的节点$v$应当对其邻接节点$u$所给予的关注。这里和原文的表述”connective strength”不同是因为我认为连通性更像是一个对称的度量方式，而其实这里关注度的给出是可以非对称的。GAT中计算该关注度的方法为：</p>
<script type="math/tex; mode=display">
\alpha_{v u}^{(k)}=\operatorname{softmax}\left(g\left(\mathbf{a}^{T}\left[\mathbf{W}^{(k)} \mathbf{h}_{v}^{(k-1)} \| \mathbf{W}^{(k)} \mathbf{h}_{u}^{(k-1)}\right)\right)\right.</script><p>更进一步地，GAT采用了Multi-head Attention来提取更多不同方面的节点特征。而GAT将多个head之间的结果拼接起来就以为它预设每个head特征之间是相同重要的。</p>
<p><a href="https://arxiv.org/pdf/1803.07294.pdf" target="_blank" rel="noopener">Gated Attention Network (GAAN)</a> introduces a self-attention mechanism which computes an additional attention score for each attention head. There are other graph attention models which might be of interest. However, they do not belong to the ConvGNN framework.</p>
<h3 id="Improvement-in-terms-of-training-efficiency"><a href="#Improvement-in-terms-of-training-efficiency" class="headerlink" title="Improvement in terms of training efficiency"></a>Improvement in terms of training efficiency</h3><p><a href="https://arxiv.org/abs/1801.10247" target="_blank" rel="noopener">Fast Learning with Graph Convolutional Network (Fast-GCN)</a> 和GraphSage不同，它在每一层sample固定数目个node来计算图卷积，而不是对每个node sample固定数目个neighbor。It interprets graph convolutions as integral transforms of embedding functions of nodes under probability measures. Monte Carlo approximation and variance reduction techniques are employed to facilitate the training process. </p>
<p><a href="https://arxiv.org/pdf/1710.10568.pdf" target="_blank" rel="noopener">Stochastic Training of Graph Convolutional Networks (StoGCN)</a></p>
<p><img src="https://i.loli.net/2020/02/27/jQ9NpSg3H67TFqC.png" alt="image.png"></p>
<h3 id="Comparison-between-spectral-and-spatial-models"><a href="#Comparison-between-spectral-and-spatial-models" class="headerlink" title="Comparison between spectral and spatial models"></a>Comparison between spectral and spatial models</h3><ul>
<li>首先，spectral-based models的效率不如spatial-based models。spectral-based model要么需要执行特征向量计算，要么需要同时处理整个图形。空间模型则更可扩展到大型图，因为它们通过信息传播直接在图域中执行卷积。可以在一批节点而不是整个图中执行计算。</li>
<li>依赖于图傅立叶基础的spectral-based model无法很好地推广到新图。因为图拉普拉斯矩阵因不同的图而不同，一旦产生变化需要进行costly的谱分解运算。spatial-based model在每个节点上局部执行图卷积，可以在不同位置和结构之间轻松共享权重。</li>
<li>Third, spectral-based models are limited to operate on undirected graphs. Spatial-based models are more flexible to handle multi-source graph inputs such as edge inputs, directed graphs, signed graphs, and heterogeneous graphs, because these graph inputs can be incorporated into the aggregation function easily.</li>
</ul>
<h2 id="Graph-Pooling"><a href="#Graph-Pooling" class="headerlink" title="Graph Pooling"></a>Graph Pooling</h2><p>在GNN方法产生出了node feature之后，我们需要将这些node feature用于最后的下游任务。Pooling主要是通过<strong>down-sampling</strong>从而减少参数的数量来防止overfitting, permutation invariance and computational complexity issues；Readout则是从节点表示产生出图表示。这两者的原理非常相近，我们指称的pooling是这两种方法的总和。</p>
<p>现在最流行的pooling方法主要是mean/max/sum pooling，因为计算这些方法非常快。一些工作甚至采用了基于attention的pooling方法，但是这些reduction operation表现还是不尽如人意，因为这些方法无论图的结构/大小，最后生成的永远是fixed-length vector。<a href="https://arxiv.org/abs/1511.06391" target="_blank" rel="noopener">Set2Set</a>方法产生随着input变大而产生更大的memory，然后使用LSTM来结合所有的embedding，最后才使用reduction method。</p>
<p><a href="https://arxiv.org/abs/1606.09375" target="_blank" rel="noopener">Chebyshev Spectral CNN (ChebNet)</a> 中提出了一种有趣的方法：他们会首先对图的节点进行重新排列。Input graphs are first coarsened into multiple levels by the Graclus. After coarsening, the nodes of the input graph and its coarsened version are rearranged into a balanced binary tree. Arbitrarily aggregating the balanced binary tree from bottom to top will arrange similar nodes together. Pooling such a rearranged signal is much more efficient than pooling the original. <a href="https://www.cse.wustl.edu/~muhan/papers/AAAI_2018_DGCNN.pdf" target="_blank" rel="noopener">SortPooling</a>通过另一种机制来对节点进行排序。</p>
<p>The aforementioned pooling methods mainly consider graph features and ignore the structural information of graphs. <a href="https://arxiv.org/abs/1806.08804" target="_blank" rel="noopener">DiffPool</a> 提出了一种可微的pooling方法。</p>
<h2 id="Discussion-of-Theoretical-Aspects"><a href="#Discussion-of-Theoretical-Aspects" class="headerlink" title="Discussion of Theoretical Aspects"></a>Discussion of Theoretical Aspects</h2><p><strong>Receptive Field</strong>. 指的是中心节点能够“看”到多远的邻接节点。对于GCN类似的方法，每多一层graph convolution，receptive field的半径就增大1. 所以对于一个连通图来说，至少存在一个最大层数，能够让任意一个节点作为中心节点看到全局的图结构信息。</p>
<p><strong>VC Dimension</strong>. <a href="https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension" target="_blank" rel="noopener">Vapnik–Chervonenkis (VC) dimension</a> is a measure of the capacity (complexity, expressive power, richness, or flexibility) of a space of functions that can be learned by a statistical classification algorithm. It is defined as the cardinality of the largest set of points that the algorithm can shatter. 有研究者推导出GNN*如果使用sigmoid or tangent hyperbolic activation，则VC dimension为$O(p^4n^2)$，这意味着如果使用这些非线性函数，那么随着Model parameter number $p$还有节点数$n$的增加，模型的复杂度会快速升高。</p>
<p><strong>Graph Isomorphism</strong>. 如果两个图topologically identical，那我们称这两个图是同构的。<a href="https://arxiv.org/abs/1810.00826" target="_blank" rel="noopener">Graph Isomorphism Network (GIN)</a> 工作证明如果一个GNN将两个图$G_1$和$G_2$分别映射到两个不同的embedding上，那么这两个图可以通过WL-test被识别成两个异构图。该工作同时证明了GCN以及GraphSage是没有办法辨别不同的图结构的。同时该工作更进一步证明了如果一个GNN的aggregation function以及readout function都是单射（injective），那么这个GNN在辨别两个异构图的能力上和WL-test是没有差别的。</p>
<p><strong>Equivariance and Invariance</strong>. GNN在处理node-level task时必须是equivariant function，在处理graph-level task时必须是invariant function. 若用数学语言表达，假设$f(\mathbf{A}, \mathbf{X}) \in R^{n \times d}$ 是一个GNN函数，$\mathbf Q$为任意的置换矩阵。如果$f\left(\mathbf{Q} \mathbf{A} \mathbf{Q}^{T}, \mathbf{Q X}\right)=\mathbf{Q} f(\mathbf{A}, \mathbf{X})$，则为equivariant；如果$f\left(\mathbf{Q} \mathbf{A} \mathbf{Q}^{T}, \mathbf{Q X}\right)= f(\mathbf{A}, \mathbf{X})$，则为invariant。这也就是说，对于任意的节点顺序，GNN函数必须给出相对同节点的相同的结果。</p>
<h1 id="Spatial-Temporal-GNNs"><a href="#Spatial-Temporal-GNNs" class="headerlink" title="Spatial-Temporal GNNs"></a>Spatial-Temporal GNNs</h1><p>Graphs in many real-world applications are dynamic both in terms of graph structures and graph inputs. Spatial-temporal graph neural networks (STGNNs) occupy important positions <strong>in capturing the dynamicity of graphs</strong>. Methods under this category aim to model the dynamic node inputs while assuming interdependency between connected nodes. STGNNs capture spatial and temporal dependencies of a graph simultaneously. The task of STGNNs can be forecasting future node values or labels, or predicting spatial-temporal graph labels. STGNNs follow two directions, <strong>RNN-based methods</strong> and <strong>CNN-based methods</strong>.</p>
<p>假设图上的简单RNN采取以下公式进行第$t$步的隐藏层计算：</p>
<script type="math/tex; mode=display">
\mathbf{H}^{(t)}=\sigma\left(\mathbf{W} \mathbf{X}^{(t)}+\mathbf{U H}^{(t-1)}+\mathbf{b}\right)</script><p>在RNN上添加graph convolution操作即有：</p>
<script type="math/tex; mode=display">
\mathbf{H}^{(t)}=\sigma\left(\operatorname{Gconv}\left(\mathbf{X}^{(t)}, \mathbf{A} ; \mathbf{W}\right)+\operatorname{Gconv}\left(\mathbf{H}^{(t-1)}, \mathbf{A} ; \mathbf{U}\right)+\mathbf{b}\right)</script><p><strong>RNN-based approaches suffer from time-consuming iterative propagation and gradient explosion/vanishing issues.</strong> As alternative solutions, CNN-based approaches tackle spatial-temporal graphs in a non-recursive manner with the advantages of parallel computing, stable gradients, and low memory requirements.</p>
<h1 id="Future-Directions"><a href="#Future-Directions" class="headerlink" title="Future Directions"></a>Future Directions</h1><p><strong>Model Depth</strong>. CNN在视觉领域证实了网络层越多表现越好。然而研究工作显示GNN正相反。因为GNN中的节点表示不断地和周围进行传递，在理论上，足够多层的网络会让所有的节点表示拟合到一个single point. This raises the question of whether going deep is still a good strategy for learning graph data.</p>
<p><strong>Salability Trade-off</strong>. The scalability of GNNs is gained at the price of corrupting graph completeness. Whether using sampling or clustering, a model will lose part of the graph information. 采样会导致一个节点可能错过一个非常重要的节点；而聚类则导致一个节点可能失去它独特的pattern。如何平衡算法的可扩展性和图完整性是未来的一大方向。</p>
<p><strong>Heterogenity</strong>. 现在的GNN直接假设同质的图，但对于异质图来说，节点、边可能有不同的表示和输入（图像或文字）。</p>
<p><strong>Dynamicity</strong>. Graphs are in nature dynamic in a way that nodes or edges may <strong>appear or disappear</strong>, and that node/edge inputs may change time by time. New graph convolutions are needed to adapt to the dynamicity of graphs. Although the dynamicity of graphs can be partly addressed by STGNNs, few of them consider how to perform graph convolutions in the case of dynamic spatial relations.</p>

    </article>
    <!-- license  -->
    
        <div class="license-wrapper">
            <p>原文作者：<a href="http://www.shihaizhou.com">Haizhou Shi</a>
            </p><p>原文链接：<a href="http://www.shihaizhou.com/2020/02/28/Graph-Neural-Networks/">http://www.shihaizhou.com/2020/02/28/Graph-Neural-Networks/</a>
            </p><p>发表日期：<a href="http://www.shihaizhou.com/2020/02/28/Graph-Neural-Networks/">February 28th 2020, 4:43:17 pm</a>
            </p><p>更新日期：<a href="http://www.shihaizhou.com/2020/02/28/Graph-Neural-Networks/">February 28th 2020, 4:50:34 pm</a>
            </p><p>版权声明：本文采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可</p>
        </div>
    
    <!-- paginator  -->
    <ul class="post-paginator">
        <li class="next">
            
                <div class="nextSlogan">Next Post</div>
                <a href="/2020/02/28/Visual-Exploration/" title="Visual Exploration">
                    <div class="nextTitle">Visual Exploration</div>
                </a>
            
        </li>
        <li class="previous">
            
                <div class="prevSlogan">Previous Post</div>
                <a href="/2020/02/28/Graph-Attention-Networks/" title="Graph Attention Networks">
                    <div class="prevTitle">Graph Attention Networks</div>
                </a>
            
        </li>
    </ul>
    <!-- 评论插件 -->
    <!-- 来必力City版安装代码 -->

<!-- City版安装代码已完成 -->
    
    
    <!-- partial('_partial/comment/changyan') -->
    <!--PC版-->


    
    

    <!-- 评论 -->
</main>
            <!-- profile -->
            
        </div>
        <footer class="footer footer-unloaded">
    <!-- social  -->
    
    <div class="social">
        
    
        
            
                <a href="mailto:shihaizhou@zju.edu.cn" class="iconfont-archer email" title="email"></a>
            
        
    
        
            
                <a href="//github.com/WOWNICE" class="iconfont-archer github" target="_blank" title="github"></a>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
            
                <a href="/atom.xml" class="iconfont-archer rss" target="_blank" title="rss"></a>
            
        
    

    </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="hexo-power">Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></span><span class="iconfont-archer power">&#xe635;</span><span id="theme-info">theme <a href="https://github.com/fi3ework/hexo-theme-archer" target="_blank">Archer</a></span>
    </div>
    <!-- 不蒜子  -->
    
    <div class="busuanzi-container">
    
     
    <span id="busuanzi_container_site_pv">PV: <span id="busuanzi_value_site_pv"></span> :)</span>
    
    </div>
    
</footer>
    </div>
    <!-- toc -->
    
    <div class="toc-wrapper" style=
    







top:50vh;

    >
        <div class="toc-catalog">
            <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
        </div>
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Backgrounds"><span class="toc-number">1.</span> <span class="toc-text">Backgrounds</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Basics"><span class="toc-number">1.1.</span> <span class="toc-text">Basics</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Training-Frameworks"><span class="toc-number">1.2.</span> <span class="toc-text">Training Frameworks</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#RecGNNs"><span class="toc-number">2.</span> <span class="toc-text">RecGNNs</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ConvGNNs"><span class="toc-number">3.</span> <span class="toc-text">ConvGNNs</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Spectral-based-ConvGNNs"><span class="toc-number">3.1.</span> <span class="toc-text">Spectral-based ConvGNNs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spatial-based-ConvGNNs"><span class="toc-number">3.2.</span> <span class="toc-text">Spatial-based ConvGNNs</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Improvement-in-terms-of-training-efficiency"><span class="toc-number">3.2.1.</span> <span class="toc-text">Improvement in terms of training efficiency</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Comparison-between-spectral-and-spatial-models"><span class="toc-number">3.2.2.</span> <span class="toc-text">Comparison between spectral and spatial models</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Graph-Pooling"><span class="toc-number">3.3.</span> <span class="toc-text">Graph Pooling</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Discussion-of-Theoretical-Aspects"><span class="toc-number">3.4.</span> <span class="toc-text">Discussion of Theoretical Aspects</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Spatial-Temporal-GNNs"><span class="toc-number">4.</span> <span class="toc-text">Spatial-Temporal GNNs</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Future-Directions"><span class="toc-number">5.</span> <span class="toc-text">Future Directions</span></a></li></ol>
    </div>
    
    <div class="back-top iconfont-archer">&#xe639;</div>
    <div class="sidebar sidebar-hide">
    <ul class="sidebar-tabs sidebar-tabs-active-0">
        <li class="sidebar-tab-archives"><span class="iconfont-archer">&#xe67d;</span><span class="tab-name">Archive</span></li>
        <li class="sidebar-tab-tags"><span class="iconfont-archer">&#xe61b;</span><span class="tab-name">Tag</span></li>
        <li class="sidebar-tab-categories"><span class="iconfont-archer">&#xe666;</span><span class="tab-name">Cate</span></li>
    </ul>
    <div class="sidebar-content sidebar-content-show-archive">
          <div class="sidebar-panel-archives">
    <!-- 在ejs中将archive按照时间排序 -->
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <div class="total-and-search">
        <div class="total-archive">
        Total : 24
        </div>
        <!-- search  -->
        
    </div>
    
    <div class="post-archive">
    
    
    
    
    <div class="archive-year"> 2020 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/10</span><a class="archive-post-title" href="/2020/05/10/MI-Estimator/">MI Estimator and Information Theory Stuff</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/09</span><a class="archive-post-title" href="/2020/05/09/InfoGraph-USL-and-Semi-SL-Graph-Level-Representation-Learning/">InfoGraph - USL and Semi-SL Graph-Level Representation Learning</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/08</span><a class="archive-post-title" href="/2020/05/08/Graph-Level-Representation-Learning-via-Graph-Graph-Proximity/">Graph-Level Representation Learning via Graph-Graph Proximity</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/03</span><a class="archive-post-title" href="/2020/05/03/BERT/">BERT</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/03</span><a class="archive-post-title" href="/2020/05/03/ELMo-Deep-Contextualized-Word-Representations/">ELMo - Deep Contextualized Word Representations</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/06</span><a class="archive-post-title" href="/2020/03/06/RSA-Algorithm/">RSA Algorithm</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/03</span><a class="archive-post-title" href="/2020/03/03/Graph-Problems/">Subgraph Related</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/29</span><a class="archive-post-title" href="/2020/02/29/How-Powerful-are-GNNs/">How Powerful are GNNs?</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/28</span><a class="archive-post-title" href="/2020/02/28/Graph-Neural-Networks/">Graph Neural Networks - Survey</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/28</span><a class="archive-post-title" href="/2020/02/28/Visual-Exploration/">Visual Exploration</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/28</span><a class="archive-post-title" href="/2020/02/28/Graph-Attention-Networks/">Graph Attention Networks</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/25</span><a class="archive-post-title" href="/2020/02/25/Graph-Convolutional-Neural-Networks/">Graph Convolutional Neural Networks</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/24</span><a class="archive-post-title" href="/2020/02/24/Transformer-Basics/">Transformer Basics</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/23</span><a class="archive-post-title" href="/2020/02/23/Algorithms-and-Grammar-of-java/">Grammar of Java</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> Invalid date </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">Invalid date</span><a class="archive-post-title" href="/2019/07/30/Google-Football-Warm-Start/">Google Football Warm Start</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2020 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/22</span><a class="archive-post-title" href="/2020/02/22/Graph-Neural-Networks-Basics/">Graph Neural Networks - Basics</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/17</span><a class="archive-post-title" href="/2020/02/17/Information-Theory-Simple-Concepts/">Information Theory</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/11</span><a class="archive-post-title" href="/2020/02/11/Some-Maths/">Metric Space</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2019 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/04</span><a class="archive-post-title" href="/2019/09/04/RL-Course-Lesson-4-Value-Function-Approximation/">RL(4) - Value Function Approximation</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/15</span><a class="archive-post-title" href="/2019/08/15/RL-Course-Lesson-3-Model-Free-Control/">RL(3) - Model-Free Control</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/13</span><a class="archive-post-title" href="/2019/08/13/Notes-on-Emergent-Communication-Through-Negotiation/">Emergent Communication Through Negotiation</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">07/15</span><a class="archive-post-title" href="/2019/07/15/RL-Course-Lesson-2-Model-Free-Policy-Evaluation/">RL(2) - Model-Free Policy Evaluation</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">07/10</span><a class="archive-post-title" href="/2019/07/10/RL-Course-Lesson-1-MP-MRP-MDP/">RL(1) - MP, MRP, MDP</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/12</span><a class="archive-post-title" href="/2019/06/12/Google-Research-Football-RL-Environment/">Google Research Football - RL Environment</a>
        </li>
    
    </ul></div>
  </div>
        <div class="sidebar-panel-tags">
    <div class="sidebar-tags-name">
    
        <span class="sidebar-tag-name" data-tags="poker"><span class="iconfont-archer">&#xe606;</span>poker</span>
    
        <span class="sidebar-tag-name" data-tags="GNN"><span class="iconfont-archer">&#xe606;</span>GNN</span>
    
        <span class="sidebar-tag-name" data-tags="ML"><span class="iconfont-archer">&#xe606;</span>ML</span>
    
        <span class="sidebar-tag-name" data-tags="overview"><span class="iconfont-archer">&#xe606;</span>overview</span>
    
        <span class="sidebar-tag-name" data-tags="FL"><span class="iconfont-archer">&#xe606;</span>FL</span>
    
        <span class="sidebar-tag-name" data-tags="RL"><span class="iconfont-archer">&#xe606;</span>RL</span>
    
        <span class="sidebar-tag-name" data-tags="Basics"><span class="iconfont-archer">&#xe606;</span>Basics</span>
    
        <span class="sidebar-tag-name" data-tags="reality"><span class="iconfont-archer">&#xe606;</span>reality</span>
    
        <span class="sidebar-tag-name" data-tags="NLP"><span class="iconfont-archer">&#xe606;</span>NLP</span>
    
        <span class="sidebar-tag-name" data-tags="paper"><span class="iconfont-archer">&#xe606;</span>paper</span>
    
        <span class="sidebar-tag-name" data-tags="notes"><span class="iconfont-archer">&#xe606;</span>notes</span>
    
        <span class="sidebar-tag-name" data-tags="Negotiation"><span class="iconfont-archer">&#xe606;</span>Negotiation</span>
    
        <span class="sidebar-tag-name" data-tags="CV"><span class="iconfont-archer">&#xe606;</span>CV</span>
    
    </div>
    <div class="iconfont-archer sidebar-tags-empty">&#xe678;</div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
    缺失模块。<br>
    1、请确保node版本大于6.2<br>
    2、在博客根目录（注意不是archer根目录）执行以下命令：<br>
    <span style="color: #f75357; font-size: 1rem; line-height: 2rem;">npm i hexo-generator-json-content --save</span><br>
    3、在根目录_config.yml里添加配置：
    <pre style="color: #787878; font-size: 0.6rem;">
jsonContent:
  meta: false
  pages: false
  posts:
    title: true
    date: true
    path: true
    text: false
    raw: false
    content: false
    slug: false
    updated: false
    comments: false
    link: false
    permalink: false
    excerpt: false
    categories: true
    tags: true</pre>
    </div> 
    <div class="sidebar-tags-list"></div>
</div>
        <div class="sidebar-panel-categories">
    <div class="sidebar-categories-name">
    
    </div>
    <div class="iconfont-archer sidebar-categories-empty">&#xe678;</div>
    <div class="sidebar-categories-list"></div>
</div>
    </div>
</div> 
    <script>
    var siteMeta = {
        root: "/",
        author: "Haizhou Shi"
    }
</script>
    <!-- CDN failover -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
    <script type="text/javascript">
        if (typeof window.$ === 'undefined')
        {
            console.warn('jquery load from jsdelivr failed, will load local script')
            document.write('<script src="/lib/jquery.min.js">\x3C/script>')
        }
    </script>
    <script src="/scripts/main.js"></script>
    <!-- algolia -->
    
    <!-- busuanzi  -->
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    <!-- CNZZ  -->
    
    </div>
    <!-- async load share.js -->
    
        <script src="/scripts/share.js" async></script>    
     
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!--script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


</body>
</html>


